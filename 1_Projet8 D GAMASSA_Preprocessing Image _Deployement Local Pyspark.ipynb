{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a247388",
   "metadata": {},
   "source": [
    "# Projet_8: NOTEBOOK DE PREPROCESSING IMAGES "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b167c7",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d04e35",
   "metadata": {},
   "source": [
    "La préparation des données (ou data processing, en anglais) consiste à rassembler, combiner, structurer et organiser les données afin de pouvoir les analyser dans le cadre de programmes d'informatique décisionnelle (BI, Business Intelligence) et d'analytique métier (BA, Business Analytics).\n",
    "\n",
    "Le travail de préparation est effectué par les équipes des services IT et BI, qui intègrent des ensembles de données pour les charger dans un entrepôt de données, une base de données  ou un référentiel sous forme de lac de données Hadoop\n",
    "\n",
    "L'un des principaux objectifs de la préparation des données consiste à assurer que les informations concernées sont exactes et cohérentes, afin que les applications BI et BA donnent des résultats pertinents.\n",
    "\n",
    "Dans les applications de Big Data, la préparation des données est généralement une tâche automatisée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3376441c",
   "metadata": {},
   "source": [
    "# 2 Importation des Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b9af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277671f",
   "metadata": {},
   "source": [
    "# 3 Localisation du repertoire de developpement de nos scripts sur notre environnement local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb07e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa411d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dgama\\\\Desktop\\\\OPENCLASSROOMS_INFO\\\\REPERTOIRE_P8_BIS'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2b87a",
   "metadata": {},
   "source": [
    "# 4 Création d'un repertoire DataLake de notre environnement local dénommé \"Input_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383eb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Input_Data\"):\n",
    "    # if the demo_folder directory is not present \n",
    "    # then create it.\n",
    "    os.makedirs(\"Input_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7156f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_Input_Data = cwd +'/'+ \"Input_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b258345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test', 'Training', 'Validation']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir( Path_Input_Data )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b12ea",
   "metadata": {},
   "source": [
    "# 5 Exploration des données images collectées  dans le repertoire Test fourni par Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac20aa8",
   "metadata": {},
   "source": [
    "## 5_1 Etape1 : Effectuons une copie du datalakedans notre environnement local repertoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b725a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.copytree('C:\\\\Users\\\\dgama\\\\Desktop\\\\OPENCLASSROOMS_INFO\\\\REPERTOIRE_P8_BIS\\\\Input_Data','C:\\\\Users\\\\dgama\\\\Desktop\\\\OPENCLASSROOMS_INFO\\\\REPERTOIRE_P8_BIS\\\\Input_Data_Backup')\n",
    "except FileExistsError:\n",
    "   # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22885be",
   "metadata": {},
   "source": [
    "## 5_2 Etape2 : Effectuons une copie du sous repertoire Test comprise dans notre datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38fabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.copytree('C:\\\\Users\\\\dgama\\\\Desktop\\\\OPENCLASSROOMS_INFO\\\\REPERTOIRE_P8_BIS\\\\Input_Data\\\\Test','C:\\\\Users\\\\dgama\\\\Desktop\\\\OPENCLASSROOMS_INFO\\\\REPERTOIRE_P8_BIS\\\\Test_Backup')\n",
    "except FileExistsError:\n",
    "   # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d80e36",
   "metadata": {},
   "source": [
    "## 5_3 Etape3 : Effectuons une exploration de l'effectif et taille de nos données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3235f11c",
   "metadata": {},
   "source": [
    "### 5_3_1_Etape3-1: Evaluation du nombre de fichiers images dans le sous repertoire Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e226420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple_6', 'apple_braeburn_1', 'apple_crimson_snow_1', 'apple_golden_1', 'apple_golden_2', 'apple_golden_3', 'apple_granny_smith_1', 'apple_hit_1', 'apple_pink_lady_1', 'apple_red_1', 'apple_red_2', 'apple_red_3', 'apple_red_delicios_1', 'apple_red_yellow_1', 'apple_rotten_1', 'cabbage_white_1', 'carrot_1', 'cucumber_1', 'cucumber_3', 'eggplant_violet_1', 'pear_1', 'pear_3', 'zucchini_1', 'zucchini_dark_1']\n",
      "\n",
      " Nous avons détécté 24 catégories de fruits dans notre base de donnée\n"
     ]
    }
   ],
   "source": [
    "lst_folder=os.listdir(\"Test_Backup\")\n",
    "print(lst_folder)\n",
    "len(lst_folder)\n",
    "print(f\"\\n Nous avons détécté {len(lst_folder)} catégories de fruits dans notre base de donnée\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b75579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons détécté 3110 image de fruits dans notre base de donnée Test\n",
      "\n",
      "Nous allons en extraire 10% pour notre projet soit 300 images à peu près\n"
     ]
    }
   ],
   "source": [
    "Count=0\n",
    "for dirpath, dirs, files in os.walk(\"Test_backup\"):\n",
    "    Count+=len(files)\n",
    "print(f\"Nous avons détécté {Count} image de fruits dans notre base de donnée Test\"  )\n",
    "print(f\"\\nNous allons en extraire 10% pour notre projet soit 300 images à peu près\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ce810",
   "metadata": {},
   "source": [
    "### 5_3_2_ Etape3-2: Evaluation  du nombre de fichiers images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9613fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_In_Backup = cwd +'\\\\'+ \"Input_Data_Backup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa17219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test', 'Training', 'Validation']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir( Path_In_Backup )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b2db8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Test****\n",
      "apple_6: 157\n",
      "Total: 157\n",
      "apple_braeburn_1: 160\n",
      "Total: 317\n",
      "apple_crimson_snow_1: 159\n",
      "Total: 476\n",
      "apple_golden_1: 154\n",
      "Total: 630\n",
      "apple_golden_2: 154\n",
      "Total: 784\n",
      "apple_golden_3: 158\n",
      "Total: 942\n",
      "apple_granny_smith_1: 160\n",
      "Total: 1102\n",
      "apple_hit_1: 234\n",
      "Total: 1336\n",
      "apple_pink_lady_1: 156\n",
      "Total: 1492\n",
      "apple_red_1: 154\n",
      "Total: 1646\n",
      "apple_red_2: 159\n",
      "Total: 1805\n",
      "apple_red_3: 140\n",
      "Total: 1945\n",
      "apple_red_delicios_1: 150\n",
      "Total: 2095\n",
      "apple_red_yellow_1: 154\n",
      "Total: 2249\n",
      "apple_rotten_1: 159\n",
      "Total: 2408\n",
      "cabbage_white_1: 47\n",
      "Total: 2455\n",
      "carrot_1: 50\n",
      "Total: 2505\n",
      "cucumber_1: 50\n",
      "Total: 2555\n",
      "cucumber_3: 81\n",
      "Total: 2636\n",
      "eggplant_violet_1: 80\n",
      "Total: 2716\n",
      "pear_1: 162\n",
      "Total: 2878\n",
      "pear_3: 72\n",
      "Total: 2950\n",
      "zucchini_1: 80\n",
      "Total: 3030\n",
      "zucchini_dark_1: 80\n",
      "Total: 3110\n",
      "\n",
      "***Training****\n",
      "apple_6: 315\n",
      "Total: 3425\n",
      "apple_braeburn_1: 320\n",
      "Total: 3745\n",
      "apple_crimson_snow_1: 318\n",
      "Total: 4063\n",
      "apple_golden_1: 308\n",
      "Total: 4371\n",
      "apple_golden_2: 308\n",
      "Total: 4679\n",
      "apple_golden_3: 316\n",
      "Total: 4995\n",
      "apple_granny_smith_1: 320\n",
      "Total: 5315\n",
      "apple_hit_1: 468\n",
      "Total: 5783\n",
      "apple_pink_lady_1: 313\n",
      "Total: 6096\n",
      "apple_red_1: 309\n",
      "Total: 6405\n",
      "apple_red_2: 318\n",
      "Total: 6723\n",
      "apple_red_3: 281\n",
      "Total: 7004\n",
      "apple_red_delicios_1: 300\n",
      "Total: 7304\n",
      "apple_red_yellow_1: 308\n",
      "Total: 7612\n",
      "apple_rotten_1: 319\n",
      "Total: 7931\n",
      "cabbage_white_1: 96\n",
      "Total: 8027\n",
      "carrot_1: 101\n",
      "Total: 8128\n",
      "cucumber_1: 100\n",
      "Total: 8228\n",
      "cucumber_3: 163\n",
      "Total: 8391\n",
      "eggplant_violet_1: 160\n",
      "Total: 8551\n",
      "pear_1: 326\n",
      "Total: 8877\n",
      "pear_3: 144\n",
      "Total: 9021\n",
      "zucchini_1: 160\n",
      "Total: 9181\n",
      "zucchini_dark_1: 160\n",
      "Total: 9341\n",
      "\n",
      "***Validation****\n",
      "apple_6: 158\n",
      "Total: 9499\n",
      "apple_braeburn_1: 160\n",
      "Total: 9659\n",
      "apple_crimson_snow_1: 159\n",
      "Total: 9818\n",
      "apple_golden_1: 154\n",
      "Total: 9972\n",
      "apple_golden_2: 154\n",
      "Total: 10126\n",
      "apple_golden_3: 158\n",
      "Total: 10284\n",
      "apple_granny_smith_1: 160\n",
      "Total: 10444\n",
      "apple_hit_1: 234\n",
      "Total: 10678\n",
      "apple_pink_lady_1: 156\n",
      "Total: 10834\n",
      "apple_red_1: 155\n",
      "Total: 10989\n",
      "apple_red_2: 159\n",
      "Total: 11148\n",
      "apple_red_3: 141\n",
      "Total: 11289\n",
      "apple_red_delicios_1: 150\n",
      "Total: 11439\n",
      "apple_red_yellow_1: 154\n",
      "Total: 11593\n",
      "apple_rotten_1: 160\n",
      "Total: 11753\n",
      "cabbage_white_1: 48\n",
      "Total: 11801\n",
      "carrot_1: 50\n",
      "Total: 11851\n",
      "cucumber_1: 50\n",
      "Total: 11901\n",
      "cucumber_3: 81\n",
      "Total: 11982\n",
      "eggplant_violet_1: 80\n",
      "Total: 12062\n",
      "pear_1: 162\n",
      "Total: 12224\n",
      "pear_3: 71\n",
      "Total: 12295\n",
      "zucchini_1: 80\n",
      "Total: 12375\n",
      "zucchini_dark_1: 80\n",
      "Total: 12455\n",
      "\n",
      "\n",
      " Le repertoire Input_Data stocke 12455 Images dont les extractions des caractéristiques sur pyspark ne peuvent pas etre      calculées en environnement local.Nous serons obligés de déployer ces données dans un environnement Big Data. \n",
      "\n",
      "L'environnement Big Data Selectionné est:AMAZON WEB SERVICE\n",
      "\n",
      "Nous allons exploiter qu'un effectif de 300 images pour notre environnement de Test soit à peu près un echantillo de 2.5% de l'effectif total testés avantdeploiement dans un environnement de production.\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for d in os.listdir(Path_In_Backup):\n",
    "    print(f'\\n***{d}****')\n",
    "    for sub_dir in os.listdir(Path_In_Backup + \"/\" + d):\n",
    "        target_sub_dir = Path_In_Backup + '/'+ d +'/'+ sub_dir\n",
    "        files = os.listdir(target_sub_dir)\n",
    "        count = len(files)\n",
    "        total += count\n",
    "        print(f'{sub_dir}: {count}')\n",
    "        print(f'Total: {total}')\n",
    "       \n",
    "print(f\"\\n\\n Le repertoire Input_Data stocke {total} Images dont les extractions des caractéristiques sur pyspark\\\n",
    " ne peuvent pas etre      calculées en environnement local.Nous serons obligés de déployer ces données dans un environnement Big Data. \") \n",
    "\n",
    "print(\"\\nL'environnement Big Data Selectionné est:AMAZON WEB SERVICE\")\n",
    "\n",
    "print(f\"\\nNous allons exploiter qu'un effectif de 300 images pour notre environnement de Test soit à peu près un echantillo de 2.5% de l'effectif total testés avant\\\n",
    "deploiement dans un environnement de production.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e148d",
   "metadata": {},
   "source": [
    "### 5_3_3 Etape 3-3 Evaluation de la taille des metadonnées et une contrainte du Service S3 à vérifier :Pas de stokage au dela de 160Go chez AWS Cloud Service sinon négocier une demande spéciale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d3e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584962030 bytes\n"
     ]
    }
   ],
   "source": [
    "def get_size(start_path = '.'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(Path_Input_Data):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "print(get_size(), 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac539b3",
   "metadata": {},
   "source": [
    "#### Nous obtenons une taille total de fichier proche de 0.6GByte(0.6Go) ce qui est très en dessous de la contrainte de taille des fichiers à stocker dans le Simple Stockage Service AWS dénommé S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b4679",
   "metadata": {},
   "source": [
    "### 5_3_4 Evaluation du budget à consacrer à la location des services AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ba6ba",
   "metadata": {},
   "source": [
    "##### Nous avons fixé les frais de location des services Cloud Aws à 200euros Max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c98fbc",
   "metadata": {},
   "source": [
    "# 6 Transfert des 12455 images de fruits vers un repertoire unique dénommé Input_Big_Data avec sous repertoires labelisés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968b5a3",
   "metadata": {},
   "source": [
    "## 6_1 Création du repertoire Input_Big_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21fb34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Input_Big_Data\"):\n",
    "      \n",
    "    # if the demo_folder directory is not present \n",
    "    # then create it.\n",
    "    os.makedirs(\"Input_Big_Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ca95d",
   "metadata": {},
   "source": [
    "## 6_2 Script de transfert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f960d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Done\n"
     ]
    }
   ],
   "source": [
    "Path_Big_Data= cwd +'/'+ \"Input_Big_Data\"\n",
    "\n",
    "for sub_dir_ref in os.listdir(Path_Big_Data + \"/\" + \"Test\"):\n",
    "       for d in os.listdir(Path_Big_Data):\n",
    "            for sub_dir in os.listdir(Path_Big_Data + \"/\" + d):\n",
    "                if  sub_dir==sub_dir_ref:\n",
    "                        target_sub_dir = Path_Big_Data + '/'+ d +'/'+ sub_dir\n",
    "                        files = os.listdir(target_sub_dir)\n",
    "                        for file in files:\n",
    "                            source = target_sub_dir +'/'+file\n",
    "                            destination = Path_Big_Data +'/'+\"Test\" +'/'+sub_dir_ref\n",
    "                            filename = os.path.basename(source) # In order to overwrite file (if one already exists in destination),\n",
    "                            dest = os.path.join(destination,filename)#we need to specify full path for destination,\n",
    "                            shutil.move(source, dest)\n",
    "\n",
    "                else:           \n",
    "                       pass\n",
    "                    \n",
    "print(\"Job Done\")\n",
    "os.startfile(\"Input_Big_Data\")                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b7d653",
   "metadata": {},
   "source": [
    "## 6_3 Verification du transfert des 12455 images vers le datalake local de transit Input_Big_Data/Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8640b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons détécté 12455 images de fruits dans notre base de données transférées avec label   vers le sous repertoire Test rattaché au repertoire Input_Big_Data\n"
     ]
    }
   ],
   "source": [
    "Count=0\n",
    "for dirpath, dirs, files in os.walk(\"Input_Big_Data/Test\"):\n",
    "    Count+=len(files)\n",
    "print(f\"Nous avons détécté {Count} images de fruits dans notre base de données transférées avec label\\\n",
    "   vers le sous repertoire Test rattaché au repertoire Input_Big_Data\"  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e852c",
   "metadata": {},
   "source": [
    "## 6_4 Création du repertoire Input_Big_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da52137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Input_Big_Data/Test1\"):\n",
    "      \n",
    "    # if the demo_folder directory is not present \n",
    "    # then create it.\n",
    "    os.makedirs(\"Input_Big_Data/Test1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde4119",
   "metadata": {},
   "source": [
    "## 6_5 Conversion des 12455 images stockées dans le sous repertoire Input_Big_Data/Test en format 224x224 et à transférer dans le sous repertoire Input_Big_Data/Test1 ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13521b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Job Done\n"
     ]
    }
   ],
   "source": [
    "Path_Big_Data= r'C:\\Users\\dgama\\Desktop\\OPENCLASSROOMS_INFO\\REPERTOIRE_P8_BIS\\Input_Big_Data\\Test1'\n",
    "from PIL import Image\n",
    "import glob\n",
    "lst_imgbig=glob.glob(\"{0}\\**\\*.jpg\".format(Path_Big_Data),recursive=True)\n",
    "for i in lst_imgbig:\n",
    "    folder=i[81:].split(os.sep)[0]\n",
    "    img=Image.open(i)\n",
    "    img=img.resize((224,224),Image.LANCZOS)\n",
    "    if not folder in os.listdir(\"Input_Big_Data/Test1\"):\n",
    "            os.makedirs(\"Input_Big_Data/Test1/\"+ folder)\n",
    "    img.save(\"Input_Big_Data\\\\Test1\\\\\"+i[81:-4]+\".jpg\")\n",
    "    \n",
    "print(\" Job Done\")\n",
    "os.startfile(\"Input_Big_Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd777a5",
   "metadata": {},
   "source": [
    "## 6_6 Verification de l'effectif des 12455 images reformatées et transférées dans le sous repertoire Input_Big_Data/Test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75746704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons détécté 0 image de fruits au format 224x224 dans le sous repertoire Input_Big_Data/Test1\n"
     ]
    }
   ],
   "source": [
    "Count=0\n",
    "for dirpath, dirs, files in os.walk(\"Input_Big_Data/Test1\"):\n",
    "    Count+=len(files)\n",
    "        \n",
    "print(f\"Nous avons détécté {Count} image de fruits au format 224x224 dans le sous repertoire Input_Big_Data/Test1\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc65dcf",
   "metadata": {},
   "source": [
    "# 7 Conversion d'un echantillon de 3110 images de fruits  en format 224x224 et sauvegarde dans le repertoire Test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de89bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Done\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "        \n",
    "lst_imgs=[i for i in glob.glob(\"Test/**/*.jpg\")]\n",
    "for i in lst_imgs:\n",
    "    folder=i[5:-4].split(os.sep)[0]\n",
    "    img=Image.open(i)\n",
    "    img=img.resize((224,224),Image.LANCZOS)\n",
    "    if not folder in os.listdir(\"Test1\"):\n",
    "        os.makedirs(\"Test1/\"+ folder)\n",
    "    img.save(\"Test1/\"+i[5:-4]+\".jpg\")\n",
    "print(\"Job Done\")\n",
    "os.startfile(\"Test1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565a81c",
   "metadata": {},
   "source": [
    "## 7_1 Copie des 3110 images reformatées dans le repertoire Test1_Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "207e6034",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.copytree('C:\\\\Users\\\\dgama\\\\Desktop\\\\OPENCLASSROOMS_INFO\\\\REPERTOIRE_P8_BIS\\\\Test1','C:\\\\Users\\\\dgama\\\\Desktop\\\\OPENCLASSROOMS_INFO\\\\REPERTOIRE_P8_BIS\\\\Test1_Backup')\n",
    "except FileExistsError:\n",
    "   # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6207ca20",
   "metadata": {},
   "source": [
    "## 7_2 Verification de l'effectif 3110 images reformatées et transférées dans le repertoire Test1_Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eed796bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons détécté 3110 image de fruits au format 224x224 dans notre base de donnée\n"
     ]
    }
   ],
   "source": [
    "Count=0\n",
    "for dirpath, dirs, files in os.walk(\"Test1\"):\n",
    "    Count+=len(files)\n",
    "        \n",
    "print(f\"Nous avons détécté {Count} image de fruits au format 224x224 dans notre base de donnée\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bcdd24",
   "metadata": {},
   "source": [
    "# 8 Transfert d'un echantillon de 300 fichiers d' images reformatées  vers le repertoire Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2210e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(\"Test2\"):\n",
    "            os.makedirs(\"Test2\")\n",
    "    \n",
    "path_source =cwd+\"\\\\\"+\"Test1\" \n",
    "path_target=\"Test2\" \n",
    "for path_folder,dirs,files in os.walk(path_source):\n",
    "    path_fld=path_folder[66:]\n",
    "    path_file_dest= \"Test2\"+ path_fld\n",
    "    if not os.path.exists(path_file_dest):\n",
    "        os.mkdir(path_file_dest) \n",
    "        Count=0\n",
    "        for file in files:\n",
    "            if not len(os.lisdir(dest))==0:\n",
    "                Max=int(len(files)/10)\n",
    "                Count+=1\n",
    "                source =path_folder +file\n",
    "                destination = cwd + path_file_dest\n",
    "                filename = os.path.basename(source) # In order to overwrite file (if one already exists in destination),\n",
    "                dest = os.path.join(destination,filename)#we need to specify full path for destination,\n",
    "                shutil.move(source, dest)\n",
    "                if Count>Max:\n",
    "                    break \n",
    "            else:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc65aa1",
   "metadata": {},
   "source": [
    "## 8_1 Controle du transfert des 300 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33c6390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nous avons un echantillon low_Data de 295 images à exploiter sur notre environnement de Test avant deploiement Big Data \n"
     ]
    }
   ],
   "source": [
    "Count=0\n",
    "for dirpath, dirs, files in os.walk(\"Test2\"):\n",
    "    Count+=len(files)\n",
    "        \n",
    "print(f\"\\nNous avons un echantillon low_Data de {Count} images à exploiter sur notre environnement de Test\\\n",
    " avant deploiement Big Data \")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdedd1ad",
   "metadata": {},
   "source": [
    "# 9 Upload des 12455 images de fruits de notre environnement local vers  le stockage cloud AWS_S3 avec Boto3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83357521",
   "metadata": {},
   "source": [
    "### Selon notre étude la librairie python Boto3 est limitée pour le upload des métadonnées  de notre environnement local vers AWS S3 . En effet, l'automatisation du transfert  des métadonnées d'un environnement local vers un environnement Cloud AWS S3 nécessite  de faire usage des technologies de transfert Big_Data adéquats. Nous poursuivrons nos recherches en vue d'identifier les techniques et méthodes les plus adapées au transfert des métadonnées.\n",
    "### Par conséquent ,le transfert des métadonnées de l'environnement local vers l'environnement de production s'effectuera manuellement à partir des fonctions upload files ou folders de la console  AWS_S3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ef4dd",
   "metadata": {},
   "source": [
    "# 10 Upload d'un echantillon de 295 fichiers images de fruits reformatées  de notre environnement local vers le Storage Cloud cloud AWS_S3 avec Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e1f8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe45b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_Low_Data= r'C:\\Users\\dgama\\Desktop\\OPENCLASSROOMS_INFO\\REPERTOIRE_P8_BIS\\Test2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504165f",
   "metadata": {},
   "source": [
    "## 10_1 Sécurisation de l'acces_key et secret_acces dans l'environnement des variables utilisateur  de notre serveur windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5860f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_S3_CREDS = {\n",
    "    \"aws_access_key_id\":os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "    \"aws_secret_access_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c792da7",
   "metadata": {},
   "source": [
    "## 10_2 Illustration d'un Script d'upload d'un faible échantillon  de fichiers vers AWS_S3 avec Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ecf1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3',**AWS_S3_CREDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35eb2c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"apple_6\"\n",
      "\"apple_braeburn_1\"\n",
      "\"apple_crimson_snow_1\"\n",
      "\"apple_golden_1\"\n",
      "\"apple_golden_2\"\n",
      "\"apple_golden_3\"\n",
      "\"apple_granny_smith_1\"\n",
      "\"apple_hit_1\"\n",
      "\"apple_pink_lady_1\"\n",
      "\"apple_red_1\"\n",
      "\"apple_red_2\"\n",
      "\"apple_red_3\"\n",
      "\"apple_red_delicios_1\"\n",
      "\"apple_red_yellow_1\"\n",
      "\"apple_rotten_1\"\n",
      "\"cabbage_white_1\"\n",
      "\"carrot_1\"\n",
      "\"cucumber_1\"\n",
      "\"cucumber_3\"\n",
      "\"eggplant_violet_1\"\n",
      "\"pear_1\"\n",
      "\"pear_3\"\n",
      "\"zucchini_1\"\n",
      "\"zucchini_dark_1\"\n",
      "\n",
      "Job Done:All files uploaded to AWS_s3\n"
     ]
    }
   ],
   "source": [
    "s3_client=boto3.client('s3',**AWS_S3_CREDS)\n",
    "folderlist=glob.glob(\"{0}\\*\".format(Path_Low_Data))\n",
    "filelist=glob.glob(\"{0}\\**\\*.jpg\".format(Path_Low_Data),recursive=True)\n",
    "for folder in folderlist :\n",
    "    folder_s3 ='\"'+ folder[67:] +'\"'\n",
    "    print(folder_s3)\n",
    "    bucket=\"myshin\"\n",
    "    for filename in filelist:\n",
    "        key=folder_s3 +'/'+ filename.split(\"\\\\\")[-1] \n",
    "        reponse=s3_client.upload_file(Filename=filename,Bucket=bucket,Key=key)\n",
    "print(\"\\nJob Done:All files uploaded to AWS_s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd537f47",
   "metadata": {},
   "source": [
    "# 11 Bilan du preprocessing Image de notre projet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f1d29fc",
   "metadata": {},
   "source": [
    "## 11_1 Environnement Local:L'Entrepot de notre échantillon  de 295 fichiers images de fruits mis en format 224x224  est est  localisé sur dans le repertoire Test2 du serveur Windows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "027785fd",
   "metadata": {},
   "source": [
    "## 11_2 Environnement Cloud:L'Entrepot des métadonnées ,constitué de 12455 fichiers images de fruits  mis en format 224x224 ,est localisé dans le sous repertoire Input_Big_Data/Test1 du serveur windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a5923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
